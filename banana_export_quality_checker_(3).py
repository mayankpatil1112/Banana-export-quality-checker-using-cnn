# -*- coding: utf-8 -*-
"""Banana_export_quality_checker (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r2HAGzSuEzQzKUx57OkMRUblzUxvi-RS
"""

#!pip install tensorflow==2.13.1
import tensorflow as tf
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt
from IPython.display import HTML
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir("/content/drive/MyDrive/banana_export/training")

#!pip install patool
#import patoolib
#patoolib.extract_archive("banana_export.zip")

WIDTH = 213
HEIGHT= 320

from PIL import Image
BATCH_SIZE = 32
IMAGE_SIZE =(HEIGHT,WIDTH)
CHANNELS=3
EPOCHS=50

# Define data directories
data_dir = "/content/drive/MyDrive/banana_export/training/banana_export"
maturity_dir ="/content/drive/MyDrive/banana_export/training/banana_export/Maturity Classification"
quality_dir = "/content/drive/MyDrive/banana_export/training/banana_export/Quality Classification"
size_dir = "/content/drive/MyDrive/banana_export/training/banana_export/Size Classification"
view_dir = "/content/drive/MyDrive/banana_export/training/banana_export/View Classification"


class1="/content/drive/MyDrive/banana_export/training/banana_export/Quality Classification/Class 1"




# Create image data generators for each input
maturity_datagen = ImageDataGenerator(rescale=1./255)
quality_datagen = ImageDataGenerator(rescale=1./255)
size_datagen = ImageDataGenerator(rescale=1./255)
view_datagen = ImageDataGenerator(rescale=1./255)

# Generate training and validation data for each input
maturity_train_generator = maturity_datagen.flow_from_directory(
    maturity_dir,
    target_size=(320,213),
    batch_size=32,
    class_mode='categorical')


quality_train_generator = quality_datagen.flow_from_directory(
    quality_dir,
    target_size=(320,213),
    batch_size=32,
    class_mode='categorical')


size_train_generator = quality_datagen.flow_from_directory(
    size_dir,
    target_size=(320,213),
    batch_size=32,
    class_mode='categorical')



view_train_generator = quality_datagen.flow_from_directory(
    view_dir,
    target_size=(320,213),
    batch_size=32,
    class_mode='categorical')


# Combine generators for training and validation
train_generator = zip(maturity_train_generator, quality_train_generator, size_train_generator, view_train_generator)



print(os.path.getsize(data_dir))

# Get class names for maturity
maturity_class_names = list(maturity_train_generator.class_indices.keys())
print("Maturity Classes:", maturity_class_names)

# Get class names for quality
quality_class_names = list(quality_train_generator.class_indices.keys())
print("Quality Classes:", quality_class_names)

# Get class names for size
size_class_names = list(size_train_generator.class_indices.keys())
print("Size Classes:", size_class_names)

# Get class names for view
view_class_names = list(view_train_generator.class_indices.keys())
print("View Classes:", view_class_names)

generators = {
    "Maturity": maturity_train_generator,
    "Quality": quality_train_generator,
    "Size": size_train_generator,
    "View": view_train_generator
}

for category, generator in generators.items():
    class_names = list(generator.class_indices.keys())
    print(f"{category} Classes:", class_names)

# Get a batch of data from one of the generators (e.g., maturity_train_generator)
image_batch, labels_batch = next(maturity_train_generator)

# Print the shape of the image batch
print("Image batch shape:", image_batch.shape)

# Get a batch of data from one of the generators (e.g., maturity_train_generator)
image_batch, labels_batch = next(maturity_train_generator)

# Print the shape of the image batch (which is a NumPy array)
print("Image batch shape:", image_batch.shape)

# You can also access the image data as a NumPy array directly:
# print(image_batch)  # This will print the entire NumPy array (might be large)
print(image_batch[0])  # This will print the first image in the batch as a NumPy array

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

# Path to the "Class 1" folder
class1_folder = "/content/drive/MyDrive/banana_export/training/banana_export/Quality Classification/Class 1"

# Get the first image file in the folder
image_file = os.listdir(class1_folder)[0]
image_path = os.path.join(class1_folder, image_file)

# Load the image using matplotlib
img = mpimg.imread(image_path)

# Display the image
plt.imshow(img)
plt.title("First Image of Class 1 (Quality Classification)")
plt.axis('off')  # Turn off axis ticks and labels
plt.show()

"""\"""

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

# Path to the "Class 1" folder
class1_folder = "/content/drive/MyDrive/banana_export/training/banana_export/Quality Classification/Class 1"

# Get the first 10 image files in the folder
image_files = os.listdir(class1_folder)[:10]

# Create a figure and subplots
fig, axes = plt.subplots(2, 5, figsize=(12, 6))  # 2 rows, 5 columns
axes = axes.ravel()  # Flatten the axes array for easier iteration

# Iterate through the image files and display them
for i, image_file in enumerate(image_files):
    image_path = os.path.join(class1_folder, image_file)
    img = mpimg.imread(image_path)
    axes[i].imshow(img)
    axes[i].set_title(f"Image {i + 1}")
    axes[i].axis('off')

plt.tight_layout()  # Adjust subplot parameters for a tight layout
plt.show()

def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):
    assert (train_split + test_split + val_split) == 1

    ds_size = len(ds)

    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=12)

    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)

    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)

    return train_ds, val_ds, test_ds

# List of folder paths
folder_paths = [
    "banana_export/Quality Classification",
    "banana_export/Size Classification",
    "banana_export/View Classification",
    "banana_export/Maturity Classification"# Add more paths as needed
]

datasets = []
for folder in folder_paths:
    dataset = tf.keras.preprocessing.image_dataset_from_directory(
        folder,
        seed=123,
        shuffle=True,
        image_size=(HEIGHT,WIDTH),
        batch_size=BATCH_SIZE
    )
    datasets.append(dataset)

# Combine all datasets into a single dataset named 'dataset'
dataset = datasets[0]
for ds in datasets[1:]:
    dataset = dataset.concatenate(ds)

'''dataset = tf.keras.preprocessing.image_dataset_from_directory(
    "banana_export/Quality Classification",
    seed=123,
    shuffle=True,
    image_size=(WIDTH,HEIGHT),
    batch_size=BATCH_SIZE
)'''

train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)

len(train_ds)

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)

resize_and_rescale = tf.keras.Sequential([
  layers.experimental.preprocessing.Resizing(HEIGHT,WIDTH),
  layers.experimental.preprocessing.Rescaling(1./255),
])

data_augmentation = tf.keras.Sequential([
  layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
  layers.experimental.preprocessing.RandomRotation(0.2),
])

train_ds = train_ds.map(
    lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)

input_shape = (BATCH_SIZE,HEIGHT,WIDTH, CHANNELS)
n_classes = 4

model = models.Sequential([
    resize_and_rescale,
    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(n_classes, activation='softmax'),
])

model.build(input_shape=input_shape)

model.summary()

model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

history = model.fit(
    train_ds,
    batch_size=BATCH_SIZE,
    validation_data=val_ds,
    verbose=1,
    epochs=50,
)



scores = model.evaluate(test_ds)

scores

history

history.params

type(history.history['loss'])

len(history.history['loss'])

history.history['loss'][:5] # show loss for first 5 epochs

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(range(EPOCHS), acc, label='Training Accuracy')
plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(EPOCHS), loss, label='Training Loss')
plt.plot(range(EPOCHS), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

import numpy as np
for images_batch, labels_batch in test_ds.take(1):

    first_image = images_batch[0].numpy().astype('uint8')
    first_label = labels_batch[0].numpy()

    print("image to predict")
    plt.imshow(first_image)
    print("actual label:",quality_class_names[first_label])

    batch_prediction = model.predict(images_batch)
    print("predicted label:",quality_class_names[np.argmax(batch_prediction[0])])
    plt.axis("off")

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = quality_class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence

plt.figure(figsize=(15, 15))
for images, labels in test_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))

        predicted_class, confidence = predict(model, images[i].numpy())
        actual_class = quality_class_names[labels[i]]

        plt.title(f"Actual quality: {actual_class},\n Predicted quality: {predicted_class}.\n Confidence: {confidence}%")

        plt.axis("off")

#i want to deployed this model on gradio


import os

# Create the 'models' directory if it doesn't exist
if not os.path.exists("../models4"):
    os.makedirs("../models4")

# Now list the contents and proceed
model_version=max([int(i) for i in os.listdir("../models4") + [0]])+2
model.save(f"../models4/{model_version}")

model.save("../banana_final.h5")



#!pip install gradio==3.39.0

# Commented out IPython magic to ensure Python compatibility.
import gradio as gr
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
import numpy as np
import argparse
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline

'''def predict_banana(image):
  img_array = tf.keras.preprocessing.image.img_to_array(image)
  img_array = tf.expand_dims(img_array, 0)
  img_array = tf.image.resize(img_array, (WIDTH, HEIGHT))  # Resize if needed
  img_array = img_array / 255.0  # Rescale

  predictions = model.predict(img_array)
  predicted_class = quality_class_names[np.argmax(predictions[0])]
  confidence = round(100 * (np.max(predictions[0])), 2)

  return f"Predicted quality: {predicted_class}, Confidence: {confidence}%"
  '''

'''iface = gr.Interface(
    fn=predict_banana,
    inputs=gr.Image(type="pil"),
    outputs="text",
    title="Banana Quality Classification",
    description="Upload an image of a banana to classify its quality."
)'''

#iface.launch()

#!pip install gradio==3.39.0

from google.colab import drive
drive.mount('/content/drive')
import os
os.chdir("/content/drive/MyDrive/banana_export/training")

# # load the model
print("[INFO] loading network and...")
model = load_model("../banana_final.h5".format(40))


def predict_image(image):
    # pre-process the image for classification
    image = cv2.resize(image, (213,320))
    image = image.astype("float") / 255.0
    image = img_to_array(image)
    image = np.expand_dims(image, axis=0)

    preds = model.predict(image)[0]
    result = dict()
    result["export banana quality"] = round(float(list(preds)[0]), 3)
    result["domestic banana quality "] = round(float(list(preds)[1]), 3)
    result["reject banana quality "] = round(float(list(preds)[2]), 3)

    print(result)
    return result


im = gr.Image()
label = gr.Label(num_top_classes=3)
gr.Interface(fn=predict_image, inputs=im, outputs=label, title="export quality").launch(share=True, debug=True)









































































